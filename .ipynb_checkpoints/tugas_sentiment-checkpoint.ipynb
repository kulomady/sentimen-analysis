{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk\n",
    "import re\n",
    "from spacy.lang.id import Indonesian\n",
    "import spacy\n",
    "from Sastrawi.StopWordRemover.StopWordRemoverFactory import StopWordRemoverFactory\n",
    "from nltk.tokenize import sent_tokenize, word_tokenize\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "stop_factory = StopWordRemoverFactory()\n",
    "stopwords = stop_factory.get_stop_words()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(203, 2)"
      ]
     },
     "execution_count": 82,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv(\"jokowi.csv\", encoding = \"ISO-8859-1\", names = ['tweet', 'sentiment'], na_values= ' ')\n",
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>tweet</th>\n",
       "      <th>sentiment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>RT @KontraS: Hai! Berjumpa lagi dengan KontraS...</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>RT @fadlizon: Bohong lagi bohong lagi. Mikrofo...</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>RT @TheCebongers: Prawobo sentil Jokowi \"Ugal2...</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>RT @bangzul_1988: @JajangRidwan19 @Hadisang70 ...</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>RT @narkosun: Jokowi dibilang ugal2an. jadi yg...</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>RT @IreneViena: Jika saya dapat membuktikan ke...</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>RT @fariji_lacak: Sdh Kubilang Dari \"AWAL. Dem...</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>RT @mkhumaini: Hampir genap empat tahun pemeri...</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>jokowi Siapa pun Cawapres  intinya Jokowi haru...</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>#2019jokowilanjut;1</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>#2019TetapJokowiâ¦\" https://t.co/HrhQwh9Kth;1</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>@marierteman @fadlizon @Metro_TV @jokowi @kem...</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>RT @MbahUyok: Sejak \"menjabat.. Anies:\" satu p...</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>Jokowi dan Greenpeace: Bagaimana Industri Diha...</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                tweet  sentiment\n",
       "1   RT @KontraS: Hai! Berjumpa lagi dengan KontraS...        1.0\n",
       "2   RT @fadlizon: Bohong lagi bohong lagi. Mikrofo...        0.0\n",
       "3   RT @TheCebongers: Prawobo sentil Jokowi \"Ugal2...        0.0\n",
       "4   RT @bangzul_1988: @JajangRidwan19 @Hadisang70 ...        NaN\n",
       "5   RT @narkosun: Jokowi dibilang ugal2an. jadi yg...        0.0\n",
       "6   RT @IreneViena: Jika saya dapat membuktikan ke...        1.0\n",
       "7   RT @fariji_lacak: Sdh Kubilang Dari \"AWAL. Dem...        0.0\n",
       "8   RT @mkhumaini: Hampir genap empat tahun pemeri...        0.0\n",
       "9   jokowi Siapa pun Cawapres  intinya Jokowi haru...        1.0\n",
       "10                                #2019jokowilanjut;1        1.0\n",
       "11     #2019TetapJokowiâ¦\" https://t.co/HrhQwh9Kth;1        1.0\n",
       "12   @marierteman @fadlizon @Metro_TV @jokowi @kem...        0.0\n",
       "13  RT @MbahUyok: Sejak \"menjabat.. Anies:\" satu p...        0.0\n",
       "14  Jokowi dan Greenpeace: Bagaimana Industri Diha...        0.0"
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[1:15]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>tweet</th>\n",
       "      <th>sentiment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>PARAHNYA DIKASI TEPUK TANGAN LAGI  BOS!!!;0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>RT @KontraS: Hai! Berjumpa lagi dengan KontraS...</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>RT @fadlizon: Bohong lagi bohong lagi. Mikrofo...</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>RT @TheCebongers: Prawobo sentil Jokowi \"Ugal2...</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>RT @narkosun: Jokowi dibilang ugal2an. jadi yg...</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>RT @IreneViena: Jika saya dapat membuktikan ke...</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>RT @fariji_lacak: Sdh Kubilang Dari \"AWAL. Dem...</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>RT @mkhumaini: Hampir genap empat tahun pemeri...</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>jokowi Siapa pun Cawapres  intinya Jokowi haru...</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               tweet  sentiment\n",
       "0        PARAHNYA DIKASI TEPUK TANGAN LAGI  BOS!!!;0        0.0\n",
       "1  RT @KontraS: Hai! Berjumpa lagi dengan KontraS...        1.0\n",
       "2  RT @fadlizon: Bohong lagi bohong lagi. Mikrofo...        0.0\n",
       "3  RT @TheCebongers: Prawobo sentil Jokowi \"Ugal2...        0.0\n",
       "5  RT @narkosun: Jokowi dibilang ugal2an. jadi yg...        0.0\n",
       "6  RT @IreneViena: Jika saya dapat membuktikan ke...        1.0\n",
       "7  RT @fariji_lacak: Sdh Kubilang Dari \"AWAL. Dem...        0.0\n",
       "8  RT @mkhumaini: Hampir genap empat tahun pemeri...        0.0\n",
       "9  jokowi Siapa pun Cawapres  intinya Jokowi haru...        1.0"
      ]
     },
     "execution_count": 88,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list(df)\n",
    "df.set_index('tweet')\n",
    "df = df.dropna()\n",
    "df "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index([], dtype='object')"
      ]
     },
     "execution_count": 89,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.columns[df.isnull().any()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cleanningTweet(text):\n",
    "    return ' '.join(re.sub(\"(@[A-Za-z0-9]+)|([^0-9A-Za-z \\t])|(\\w+:\\/\\/\\S+)|(RT)|([:1])\",\" \",text).split())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {},
   "outputs": [],
   "source": [
    "def stopwordRemove(text):\n",
    "    filtered_sentence = [w for w in text if not w in stopwords]\n",
    "    resultStringTokenize = ''.join(filtered_sentence)\n",
    "    return resultStringTokenize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "metadata": {},
   "outputs": [],
   "source": [
    "def stemmingWord(sentence):\n",
    "    nlp = Indonesian()  # use directly\n",
    "    nlp = spacy.blank('id')  # blank instance'\n",
    "    text = nlp(sentence)\n",
    "    token_kata = [token.lemma_ for token in text]\n",
    "    resultWithSpacy = ' '.join(token_kata)\n",
    "    return resultWithSpacy.lower()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "metadata": {},
   "outputs": [],
   "source": [
    "def prepocessingText(text):\n",
    "    return stemmingWord(stopwordRemove(cleanningTweet(text)))\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_df = df.fillna(method=\"ffill\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "metadata": {},
   "outputs": [],
   "source": [
    "inp = [{'c1':10, 'c2':100}, {'c1':11,'c2':110}, {'c1':12,'c2':120}]\n",
    "\n",
    "all_data = []\n",
    "for index, row in new_df.iterrows():\n",
    "    all_data.append(tuple((prepocessingText(row['tweet']), row['sentiment'])))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sentiment</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>parahnya dikasi tepuk tangan lagi bos 0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>hai berjumpa lagi dengan kontras yang akan kem...</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>bohong lagi bohong lagi mikrofon dimatikan dul...</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>prawobo sentil jokowi ugal2an lalu bung adian ...</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>jokowi dibilang ugal2an jadi yg bangun infrast...</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                           sentiment  label\n",
       "0            parahnya dikasi tepuk tangan lagi bos 0    0.0\n",
       "1  hai berjumpa lagi dengan kontras yang akan kem...    1.0\n",
       "2  bohong lagi bohong lagi mikrofon dimatikan dul...    0.0\n",
       "3  prawobo sentil jokowi ugal2an lalu bung adian ...    0.0\n",
       "4  jokowi dibilang ugal2an jadi yg bangun infrast...    0.0"
      ]
     },
     "execution_count": 155,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clean_data = pd.DataFrame(all_data,  columns = [\"sentiment\", \"label\"])\n",
    "clean_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 176,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = clean_data.sentiment.str.cat(sep=' ')\n",
    "words = nltk.tokenize.word_tokenize(a)\n",
    "word_dist = nltk.FreqDist(words)\n",
    "# word_dist.most_common()\n",
    "\n",
    "# import pandas as pd\n",
    "# from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "\n",
    "# df = pd.read_table(\"/tmp/test.csv\", sep=\"\\s+\")\n",
    "# v = TfidfVectorizer()\n",
    "# x = v.fit_transform(df['text'])\n",
    "\n",
    "# df1 = pd.DataFrame(x.toarray(), columns=v.get_feature_names())\n",
    "# df.drop('text', axis=1, inplace=True)\n",
    "# res = pd.concat([df, df1], axis=1)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Stemming words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from Sastrawi.Stemmer.StemmerFactory import StemmerFactory\n",
    "\n",
    "# create stemmer\n",
    "stemmerFactory = StemmerFactory()\n",
    "stemmer = stemmerFactory.create_stemmer()\n",
    "hasilStemmer = stemmer.stem(stopwordResult)\n",
    "print(hasilStemmer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
